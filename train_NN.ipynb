{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "train_NN.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {
        "id": "yIfYedKNnWPB"
      },
      "outputs": [],
      "source": [
        "#So let's study how to make NN\n",
        "#Imports\n",
        "import torch\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import DataLoader,TensorDataset\n",
        "import torchvision.datasets as datasets\n",
        "import torchvision.transforms as transforms\n",
        "from sklearn.metrics import balanced_accuracy_score\n",
        "from sklearn.model_selection import train_test_split # just help us to make train and test dataset "
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class my_nn(nn.Module):\n",
        "  def __init__(self,open_size,input_size1,input_size2,input_size3, n_classes):\n",
        "      super(my_nn,self).__init__()\n",
        "      self.fc1 = nn.Linear(open_size,input_size1)\n",
        "      self.act1 = nn.Sigmoid()\n",
        "      self.fc2 = nn.Linear(input_size1,input_size2)\n",
        "      self.act2= nn.Sigmoid()\n",
        "      self.fc3 = nn.Linear(input_size2,input_size3)\n",
        "      self.act3 =nn.Sigmoid()\n",
        "      self.fc4 = nn.Linear(input_size3,n_classes)\n",
        "  def forward (self,x):\n",
        "    x = self.fc1(x)\n",
        "    x = self.act1(x)\n",
        "    x = self.fc2(x)\n",
        "    x = self.act2(x)\n",
        "    x = self.fc3(x)\n",
        "    x = self.act3(x)\n",
        "    x = self.fc4(x)\n",
        "    return F.log_softmax(x, dim=1)"
      ],
      "metadata": {
        "id": "pbqa9e0Bomp6"
      },
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "print(f\"Right now you used: {device}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jhCeoWopLGYc",
        "outputId": "19a4e80a-d281-4332-c4d8-18e5272762d4"
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Right now you used: cpu\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "mnist_shape = 784  #28x28\n",
        "input_size1 = 40\n",
        "input_size2 = 100\n",
        "input_size3 = 200\n",
        "n_classes = 10\n",
        "nn_my = my_nn(mnist_shape,input_size1,input_size2,input_size3,n_classes).to(device)\n",
        "print(nn_my)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sukKURNHt1UJ",
        "outputId": "4d65ecb1-0c7a-43ed-93aa-5bcb8ff8f4d8"
      },
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "my_nn(\n",
            "  (fc1): Linear(in_features=784, out_features=40, bias=True)\n",
            "  (act1): Sigmoid()\n",
            "  (fc2): Linear(in_features=40, out_features=100, bias=True)\n",
            "  (act2): Sigmoid()\n",
            "  (fc3): Linear(in_features=100, out_features=200, bias=True)\n",
            "  (act3): Sigmoid()\n",
            "  (fc4): Linear(in_features=200, out_features=10, bias=True)\n",
            ")\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "lr1 = 10**(-3)\n",
        "print(f\"learning_rate: {lr1}\")\n",
        "batch_size1 = 64 # good tone to used batch \n",
        "batch_size2 = 8"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ccMV_N0Swbc6",
        "outputId": "e909b491-10cf-4dd5-81a4-2d5e64d55b0e"
      },
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "learning_rate: 0.001\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from numpy import genfromtxt\n",
        "my_data = genfromtxt('sample_data/mnist_train_small.csv', delimiter=',') #default folder in colab"
      ],
      "metadata": {
        "id": "krQh2cFz16_x"
      },
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(my_data.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5qyXUHTJNgEM",
        "outputId": "40b9ca27-d745-409e-d527-7c7572fcf241"
      },
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(20000, 785)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_real = my_data[:,0]\n",
        "print(y_real.shape)\n",
        "\n"
      ],
      "metadata": {
        "id": "PXYx6azN21ez",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f0d93858-f20c-4a0e-b84e-fbe982181520"
      },
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(20000,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X_real = my_data[:,1:785]\n",
        "\n",
        "print(X_real.shape)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ogJSuuEcKxrb",
        "outputId": "5eabc193-19b7-4c57-d9d1-6080c799359b"
      },
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(20000, 784)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(X_real, y_real, random_state=0)"
      ],
      "metadata": {
        "id": "yR6DMG5am-f2"
      },
      "execution_count": 45,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train_t = torch.tensor(X_train/255.0)\n",
        "Y_train_t = torch.tensor(y_train) \n",
        "\n",
        "X_test_t = torch.tensor(X_test/255.0)\n",
        "Y_test_t = torch.tensor(y_test)\n",
        "train_dataset = TensorDataset(X_train_t, Y_train_t)\n",
        "test_dataset = TensorDataset(X_test_t, Y_test_t)"
      ],
      "metadata": {
        "id": "oqfy1ABS0eIR"
      },
      "execution_count": 46,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# loss_function = nn.BCEWithLogitsLoss()\n",
        "loss_function = nn.CrossEntropyLoss()\n",
        "optimaizer = optim.Adam(nn_my.parameters(),lr = lr1)"
      ],
      "metadata": {
        "id": "dB3doM0V5lMf"
      },
      "execution_count": 47,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Making data_loader \n",
        "train_dataloader = DataLoader(dataset =train_dataset, batch_size=batch_size1,shuffle=True)\n",
        "test_dataloader = DataLoader(dataset =test_dataset, batch_size=batch_size2,shuffle=True)"
      ],
      "metadata": {
        "id": "tksqAOBi9BIO"
      },
      "execution_count": 48,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def metrics_fn():\n",
        "   correct_test = 0\n",
        "   total_test = 0\n",
        "   correct_train =0\n",
        "   total_train = 0\n",
        "   with torch.no_grad():\n",
        "    for data in test_dataloader:\n",
        "        X, y = data\n",
        "        X = X.float()\n",
        "        y =y.long()\n",
        "\n",
        "        output = nn_my(X.view(-1,784))\n",
        "        for idx, i in enumerate(output):\n",
        "            if torch.argmax(i) == y[idx]:\n",
        "                correct_test += 1\n",
        "            total_test += 1\n",
        "    for data in train_dataloader:\n",
        "        X, y = data\n",
        "        X = X.float()\n",
        "        y =y.long()\n",
        "\n",
        "        output = nn_my(X.view(-1,784))\n",
        "        for idx, i in enumerate(output):\n",
        "            if torch.argmax(i) == y[idx]:\n",
        "                correct_train += 1\n",
        "            total_train += 1\n",
        "   output = nn_my(X.view(-1,784))  \n",
        "   test_loss = F.nll_loss(output, y)\n",
        "   score_on_test = round(correct_test/total_test, 3)\n",
        "   score_on_train = round(correct_train/total_train, 3)\n",
        "\n",
        "   return score_on_test,score_on_train,test_loss\n",
        "\n",
        "\n",
        "  \n",
        "\n"
      ],
      "metadata": {
        "id": "mq8YPP5JoFNG"
      },
      "execution_count": 49,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train_fc(max_epoch,model,optimaizer,loss_function):\n",
        "  for epoch in range(max_epoch):\n",
        "    for iter, (data,target) in enumerate(train_dataloader):\n",
        "      optimaizer.zero_grad()\n",
        "      data = data.float()\n",
        "      target =target.long()\n",
        "      nn_my.zero_grad()  \n",
        "      output = nn_my(data.view(-1,784))  \n",
        "      loss = F.nll_loss(output, target)\n",
        "      loss.backward() \n",
        "      optimaizer.step()\n",
        "      if (iter + epoch * len(train_dataloader)) % 5 == 0:\n",
        "        score_on_test,score_on_train,test_loss = metrics_fn()\n",
        "        print(f\"Iteration №: {iter + epoch * len(train_dataloader)}\")\n",
        "        print(f\"loss: {loss}\")\n",
        "        print(f\"test_loss: {test_loss}\")\n",
        "        print(f\"Score_on_test_dataset: {score_on_test}\")\n",
        "        print(f\"Score_on_train_dataset: {score_on_train}\")\n",
        "\n",
        "  return loss"
      ],
      "metadata": {
        "id": "jexqJVxh7B94"
      },
      "execution_count": 91,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "losses = train_fc(1, nn_my,optimaizer,loss_function)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xNcWoXjFSEU0",
        "outputId": "eb52456d-911f-4f71-f508-7f6a420581f5"
      },
      "execution_count": 93,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Iteration №: 0\n",
            "loss: 0.19281239807605743\n",
            "test_loss: 0.7453464865684509\n",
            "Score_on_test_dataset: 0.916\n",
            "Score_on_train_dataset: 0.939\n",
            "Iteration №: 5\n",
            "loss: 0.20801511406898499\n",
            "test_loss: 0.192002072930336\n",
            "Score_on_test_dataset: 0.916\n",
            "Score_on_train_dataset: 0.938\n",
            "Iteration №: 10\n",
            "loss: 0.11152486503124237\n",
            "test_loss: 0.2419336885213852\n",
            "Score_on_test_dataset: 0.913\n",
            "Score_on_train_dataset: 0.937\n",
            "Iteration №: 15\n",
            "loss: 0.27836692333221436\n",
            "test_loss: 0.17189277708530426\n",
            "Score_on_test_dataset: 0.912\n",
            "Score_on_train_dataset: 0.936\n",
            "Iteration №: 20\n",
            "loss: 0.4780605733394623\n",
            "test_loss: 0.28226804733276367\n",
            "Score_on_test_dataset: 0.914\n",
            "Score_on_train_dataset: 0.937\n",
            "Iteration №: 25\n",
            "loss: 0.2888757288455963\n",
            "test_loss: 0.11272594332695007\n",
            "Score_on_test_dataset: 0.917\n",
            "Score_on_train_dataset: 0.939\n",
            "Iteration №: 30\n",
            "loss: 0.3123822808265686\n",
            "test_loss: 0.375681072473526\n",
            "Score_on_test_dataset: 0.915\n",
            "Score_on_train_dataset: 0.937\n",
            "Iteration №: 35\n",
            "loss: 0.12257411330938339\n",
            "test_loss: 0.11805469542741776\n",
            "Score_on_test_dataset: 0.916\n",
            "Score_on_train_dataset: 0.937\n",
            "Iteration №: 40\n",
            "loss: 0.1957937479019165\n",
            "test_loss: 0.3249489963054657\n",
            "Score_on_test_dataset: 0.915\n",
            "Score_on_train_dataset: 0.938\n",
            "Iteration №: 45\n",
            "loss: 0.16572245955467224\n",
            "test_loss: 0.12681858241558075\n",
            "Score_on_test_dataset: 0.917\n",
            "Score_on_train_dataset: 0.939\n",
            "Iteration №: 50\n",
            "loss: 0.18680164217948914\n",
            "test_loss: 0.15836139023303986\n",
            "Score_on_test_dataset: 0.916\n",
            "Score_on_train_dataset: 0.938\n",
            "Iteration №: 55\n",
            "loss: 0.4451509118080139\n",
            "test_loss: 0.47160518169403076\n",
            "Score_on_test_dataset: 0.918\n",
            "Score_on_train_dataset: 0.938\n",
            "Iteration №: 60\n",
            "loss: 0.12642571330070496\n",
            "test_loss: 0.21258674561977386\n",
            "Score_on_test_dataset: 0.919\n",
            "Score_on_train_dataset: 0.94\n",
            "Iteration №: 65\n",
            "loss: 0.13774433732032776\n",
            "test_loss: 0.4223058521747589\n",
            "Score_on_test_dataset: 0.917\n",
            "Score_on_train_dataset: 0.941\n",
            "Iteration №: 70\n",
            "loss: 0.43678343296051025\n",
            "test_loss: 0.46714529395103455\n",
            "Score_on_test_dataset: 0.914\n",
            "Score_on_train_dataset: 0.939\n",
            "Iteration №: 75\n",
            "loss: 0.2377110719680786\n",
            "test_loss: 0.2394101470708847\n",
            "Score_on_test_dataset: 0.916\n",
            "Score_on_train_dataset: 0.938\n",
            "Iteration №: 80\n",
            "loss: 0.2503434121608734\n",
            "test_loss: 0.10247200727462769\n",
            "Score_on_test_dataset: 0.917\n",
            "Score_on_train_dataset: 0.941\n",
            "Iteration №: 85\n",
            "loss: 0.22356602549552917\n",
            "test_loss: 0.29345056414604187\n",
            "Score_on_test_dataset: 0.915\n",
            "Score_on_train_dataset: 0.94\n",
            "Iteration №: 90\n",
            "loss: 0.33121201395988464\n",
            "test_loss: 0.41958150267601013\n",
            "Score_on_test_dataset: 0.916\n",
            "Score_on_train_dataset: 0.939\n",
            "Iteration №: 95\n",
            "loss: 0.14668944478034973\n",
            "test_loss: 0.15383565425872803\n",
            "Score_on_test_dataset: 0.916\n",
            "Score_on_train_dataset: 0.94\n",
            "Iteration №: 100\n",
            "loss: 0.20431530475616455\n",
            "test_loss: 0.22717469930648804\n",
            "Score_on_test_dataset: 0.913\n",
            "Score_on_train_dataset: 0.938\n",
            "Iteration №: 105\n",
            "loss: 0.3926822245121002\n",
            "test_loss: 0.3228309452533722\n",
            "Score_on_test_dataset: 0.916\n",
            "Score_on_train_dataset: 0.939\n",
            "Iteration №: 110\n",
            "loss: 0.43597108125686646\n",
            "test_loss: 0.23228375613689423\n",
            "Score_on_test_dataset: 0.916\n",
            "Score_on_train_dataset: 0.94\n",
            "Iteration №: 115\n",
            "loss: 0.141058087348938\n",
            "test_loss: 0.3402620255947113\n",
            "Score_on_test_dataset: 0.914\n",
            "Score_on_train_dataset: 0.937\n",
            "Iteration №: 120\n",
            "loss: 0.2490958869457245\n",
            "test_loss: 0.03658851236104965\n",
            "Score_on_test_dataset: 0.916\n",
            "Score_on_train_dataset: 0.941\n",
            "Iteration №: 125\n",
            "loss: 0.3537691533565521\n",
            "test_loss: 0.0776827409863472\n",
            "Score_on_test_dataset: 0.92\n",
            "Score_on_train_dataset: 0.943\n",
            "Iteration №: 130\n",
            "loss: 0.20722809433937073\n",
            "test_loss: 0.29739028215408325\n",
            "Score_on_test_dataset: 0.917\n",
            "Score_on_train_dataset: 0.941\n",
            "Iteration №: 135\n",
            "loss: 0.16552844643592834\n",
            "test_loss: 0.0860356017947197\n",
            "Score_on_test_dataset: 0.92\n",
            "Score_on_train_dataset: 0.944\n",
            "Iteration №: 140\n",
            "loss: 0.2314542829990387\n",
            "test_loss: 0.04897098243236542\n",
            "Score_on_test_dataset: 0.918\n",
            "Score_on_train_dataset: 0.945\n",
            "Iteration №: 145\n",
            "loss: 0.15247176587581635\n",
            "test_loss: 0.10270842164754868\n",
            "Score_on_test_dataset: 0.919\n",
            "Score_on_train_dataset: 0.945\n",
            "Iteration №: 150\n",
            "loss: 0.2810930609703064\n",
            "test_loss: 0.18731744587421417\n",
            "Score_on_test_dataset: 0.918\n",
            "Score_on_train_dataset: 0.945\n",
            "Iteration №: 155\n",
            "loss: 0.16129066050052643\n",
            "test_loss: 0.3658628463745117\n",
            "Score_on_test_dataset: 0.918\n",
            "Score_on_train_dataset: 0.945\n",
            "Iteration №: 160\n",
            "loss: 0.22920821607112885\n",
            "test_loss: 0.12361631542444229\n",
            "Score_on_test_dataset: 0.921\n",
            "Score_on_train_dataset: 0.944\n",
            "Iteration №: 165\n",
            "loss: 0.2965785264968872\n",
            "test_loss: 0.19558876752853394\n",
            "Score_on_test_dataset: 0.915\n",
            "Score_on_train_dataset: 0.943\n",
            "Iteration №: 170\n",
            "loss: 0.12391073256731033\n",
            "test_loss: 0.24745626747608185\n",
            "Score_on_test_dataset: 0.916\n",
            "Score_on_train_dataset: 0.942\n",
            "Iteration №: 175\n",
            "loss: 0.2191418558359146\n",
            "test_loss: 0.33046022057533264\n",
            "Score_on_test_dataset: 0.914\n",
            "Score_on_train_dataset: 0.943\n",
            "Iteration №: 180\n",
            "loss: 0.27076321840286255\n",
            "test_loss: 0.1773856282234192\n",
            "Score_on_test_dataset: 0.918\n",
            "Score_on_train_dataset: 0.944\n",
            "Iteration №: 185\n",
            "loss: 0.20113733410835266\n",
            "test_loss: 0.045947227627038956\n",
            "Score_on_test_dataset: 0.921\n",
            "Score_on_train_dataset: 0.947\n",
            "Iteration №: 190\n",
            "loss: 0.14797835052013397\n",
            "test_loss: 0.05138108506798744\n",
            "Score_on_test_dataset: 0.917\n",
            "Score_on_train_dataset: 0.943\n",
            "Iteration №: 195\n",
            "loss: 0.10560252517461777\n",
            "test_loss: 0.03910810500383377\n",
            "Score_on_test_dataset: 0.919\n",
            "Score_on_train_dataset: 0.944\n",
            "Iteration №: 200\n",
            "loss: 0.29992926120758057\n",
            "test_loss: 0.368396133184433\n",
            "Score_on_test_dataset: 0.92\n",
            "Score_on_train_dataset: 0.945\n",
            "Iteration №: 205\n",
            "loss: 0.11852296441793442\n",
            "test_loss: 0.14547672867774963\n",
            "Score_on_test_dataset: 0.92\n",
            "Score_on_train_dataset: 0.945\n",
            "Iteration №: 210\n",
            "loss: 0.21751579642295837\n",
            "test_loss: 0.4246329069137573\n",
            "Score_on_test_dataset: 0.919\n",
            "Score_on_train_dataset: 0.945\n",
            "Iteration №: 215\n",
            "loss: 0.08533953130245209\n",
            "test_loss: 0.062376752495765686\n",
            "Score_on_test_dataset: 0.92\n",
            "Score_on_train_dataset: 0.945\n",
            "Iteration №: 220\n",
            "loss: 0.15980584919452667\n",
            "test_loss: 0.24977298080921173\n",
            "Score_on_test_dataset: 0.921\n",
            "Score_on_train_dataset: 0.944\n",
            "Iteration №: 225\n",
            "loss: 0.15725119411945343\n",
            "test_loss: 0.35266175866127014\n",
            "Score_on_test_dataset: 0.921\n",
            "Score_on_train_dataset: 0.944\n",
            "Iteration №: 230\n",
            "loss: 0.10765744000673294\n",
            "test_loss: 0.04745602235198021\n",
            "Score_on_test_dataset: 0.922\n",
            "Score_on_train_dataset: 0.946\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#lets choose random number from test_dataset \n",
        "import random as lol\n",
        "\n",
        "number_rand = lol.randint(0,len(X_test))\n",
        "print(number_rand)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "X2YuEBEd_6I4",
        "outputId": "f5c2de24-60ac-4a3e-9342-58f623d783ab"
      },
      "execution_count": 87,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "4225\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# some_digit.reshape(28, 28)\n",
        "some_number= (X_test[number_rand]/255.0).reshape(28,28)\n",
        "some_number1 = X_test_t[number_rand].float()\n",
        "output = nn_my(some_number1.view(-1,784)) \n",
        "pred = output[0]\n",
        "index_is = torch.argmax(pred)\n",
        "plt.title(f\"predict number is :{index_is}, so real number is {y_test[number_rand]}\")\n",
        "plt.imshow(some_number)\n",
        "plt.show()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 280
        },
        "id": "1Qrm0UN9ygKb",
        "outputId": "c222a9ea-ef17-44ef-f01a-dbdcb6809729"
      },
      "execution_count": 88,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#So today we have done here"
      ],
      "metadata": {
        "id": "EYKDiJv2_lIp"
      }
    }
  ]
}